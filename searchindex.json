[{"content":"The Day Lasts More than a Hundred Years by Chingiz Aitmatov, translated by John French I thought this would be a science-fiction story, because I vaguely remember phrases like \u0026ldquo;aliens\u0026rdquo; and \u0026ldquo;building rockets around the world\u0026rdquo; when I first saw it in a random booklist. But it\u0026rsquo;s actually first of all a story about a man\u0026rsquo;s life in the Soviet Union, and the life and deaths of his friends. It happens in the Soviet Union, but this story is not set at the center of it. Not the glorious Motherland Russia that started the revolution, but in Kazakhstan, where religion, traditions, and old legends are perhaps a bit more at odds with the Soviet ideals.\nIt\u0026rsquo;s a somber story, although at times it feels like an elaborate Soviet joke, with both the story teller and the listener aware of the hopelessness of it all, but still making the most out of the situation. Life goes on and there must be hope for the future somewhere.\nThis is, in my opinion, a much better book than How the Steel was Tempered, which was a mandatory read for school kids in China (at least back in the days). I wish I had the pleasure of reading Aitmatov\u0026rsquo;s story instead.\nThis bit interesting commentary came from the book\u0026rsquo;s preface, written by the author himself (this book was published in 1988):\nA man without a sense of history, without memory of the past, who is forced to reconsider his place in the world, a man deprived of the historic experience of his own and other peoples, lacks any perspective and can only live for the present, for the day. To prove this, one has only to recall the ‘Cultural Revolution’ in China, which manipulated the consciousness of the people and reduced the many complications of life to the level of quotations from the so-called little Red books of Mao. Here, the ancient traditions of the people clashed with the hegemonic policies of the then Chinese government. Paradoxically this denial or falsification of the past went hand in hand with a self-satisfied, boastful chauvinism. The result was isolation; for only behind a real or metaphorical Wall of China can one preserve the myth of the superiority of one people over all others.\nThis is such a sick burn given today\u0026rsquo;s politics. Some thirty years later both the real and metaphorical Wall of China is getting higher and thicker than ever. I guess thirty years is still too little time to really learn anything, especially if you\u0026rsquo;re not trying very hard.\n","date":"14 October, 2021","id":0,"permalink":"/reading-notes/2021-10-14-the_day_lasts_more_than_a_hundred_years/","summary":"\u003ch3 id=\"the-day-lasts-more-than-a-hundred-years\"\u003e\u003ca href=\"https://www.goodreads.com/book/show/366889.The_Day_Lasts_More_Than_a_Hundred_Years\"\u003e\u003cem\u003eThe Day Lasts More than a Hundred Years\u003c/em\u003e by Chingiz Aitmatov, translated by John French\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eI thought this would be a science-fiction story, because I vaguely remember phrases like \u0026ldquo;aliens\u0026rdquo; and \u0026ldquo;building rockets around the world\u0026rdquo; when I first saw it in a random booklist.\nBut it\u0026rsquo;s actually first of all a story about a man\u0026rsquo;s life in the Soviet Union, and the life and deaths of his friends.\nIt happens in the Soviet Union, but this story is not set at the center of it. Not the glorious Motherland Russia that started the revolution, but in Kazakhstan, where religion, traditions, and old legends are perhaps a bit more at odds with the Soviet ideals.\u003c/p\u003e","tags":"","title":"The Day Lasts More than a Hundred Years"},{"content":"I\u0026rsquo;ve never been the biggest fan of Liu Cixin, even though he\u0026rsquo;s often heralded as \u0026ldquo;the best sci-fi author in China\u0026rdquo;. He does (sometimes) demonstrate interesting ideas by combining scientific concepts and imagination, but in my opinion that\u0026rsquo;s not quite enough to be a good sci-fi story. In particular, these two elements in his writings always leave me feeling irritated, if not downright angry:\nHelpless female characters with a \u0026ldquo;pure\u0026rdquo; mind (and body)\nI can accept it if the men are always the hero \u0026mdash; that\u0026rsquo;s not uncommon in most fiction, especially from his time. But I cannot accept how women are depicted in his stories: silly, helpless, and they just don\u0026rsquo;t really do anything apart from waiting and hoping and praying. All his female characters seem to come straight from the damsel in distress trope, with little thoughts or desires of their own.\nInterestingly, in this translated version, the hero in a few of the stories have the opposite gender as compared to the original Chinese stories: e.g. The Time Migration. I guess the translator is tired of this gender stereotype as well!\nCorruption? What corruption!\nLiu often set his stories against a backdrop that\u0026rsquo;s somewhat reminiscient of the typical communist China: the people are suffering, the system is not working, and yet there\u0026rsquo;s still rampant corruption.\nThe heros of this stories recognize this corruption and wants to make a difference, but in the end they still go along with the corrupted ways because that\u0026rsquo;s the only way to move forward for the \u0026ldquo;greater good\u0026rdquo;. There is some serious mental gymnastics happening:\nThis is not working, and I want to fix it! But that would mean bringing changes to a lot of people! There\u0026rsquo;s no way other people can accept changes! So I better stick to how things work now! Now I\u0026rsquo;ll also be praised by my boss/elder, because accepting the reality shows that I\u0026rsquo;m being mature! I\u0026rsquo;ve witnessed this in my life under many different circumstances, and I\u0026rsquo;m still incapable of this mental gymnastics. Guess who\u0026rsquo;s not mature :-/.\nMaybe it was his intention to irritate his readers to make them reflect and confront the reality, but I highly doubt that. For me it\u0026rsquo;s more likely that this is just him being true to his heart.\n","date":"10 April, 2021","id":1,"permalink":"/reading-notes/2021-04-10-liu_cixin/","summary":"\u003cp\u003eI\u0026rsquo;ve never been the biggest fan of \u003ca href=\"https://en.wikipedia.org/wiki/Liu_Cixin\"\u003eLiu Cixin\u003c/a\u003e,\neven though he\u0026rsquo;s often heralded as \u0026ldquo;the best sci-fi author in China\u0026rdquo;.\nHe does (sometimes) demonstrate interesting ideas by combining scientific concepts and imagination,\nbut in my opinion that\u0026rsquo;s not quite enough to be a good sci-fi story.\nIn particular,\nthese two elements in his writings always leave me feeling irritated,\nif not downright angry:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eHelpless female characters with a \u0026ldquo;pure\u0026rdquo; mind (and body)\u003c/p\u003e","tags":"","title":"Works by Liu Cixin"},{"content":"\nTotoros, gouache\n","date":"29 March, 2021","id":2,"permalink":"/sketchbook/2021-03-29_totoros/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2021-03-29_totoros.jpg\" alt=\"Totoros\" title=\"Totoros\"\u003e\u003c/p\u003e","tags":"","title":"Totoros"},{"content":"Slaughterhouse-Five by Kurt Vonnegut Jr. I picked up a random book by Kurt Vonnegut Jr., expecting a science-fiction type of story, but instead got a book about war.\nI never liked books or movies about war, they glorify it by telling stories of heroes and their gallantry, whereas the dead sidekicks and other collateral damages barely constitute an afterthought.\nI\u0026rsquo;d hate to be such a sidekick, and hate it even more if I were such a hero.\nWar is so ridiculously pointless and painful, and it always happens because somehow people are lead to think that wars can solve problems. I\u0026rsquo;m not a student of history or of the human psyche, but it seems to me that at every chance where an in-group/out-group distinction can be made, someone will inevitably feel the need to assert the superiority of their own group identity, by launching wars of some form. What\u0026rsquo;s especially sad is most often people never actually try to get to know know the other side, the human beings they are trying to persecute.\nI also just realised that I\u0026rsquo;ve read a lot more stories about WW2 from the perspective of Europeans and Americans than stories from Asia-Pacific, even though the war there lasted longer and is no less gruesome.\nI can\u0026rsquo;t recall any Chinese book that tries to combine personal experience of the war with some elements of fiction (I\u0026rsquo;m sure they exist, but just somehow never crossed my path), or any other book that tries to uncover the futility of war. Maybe at that point in China wars of different shapes and forms had been going on for too long and desensitised the people living through them. Also I think part of the reason is there was never any serious, deep-level reconciliation between China and Japan, and on the other hand the current government in China is more than happy to exploit this piece of history for their \u0026ldquo;patriotic education\u0026rdquo;.\nI\u0026rsquo;ve also never explored Korean or south-east Asian literatures so I know very little about what happened there. And I also don\u0026rsquo;t know how Japan as a country feels about that period, but maybe these books can shed some light - I\u0026rsquo;ll read them later:\nMemoirs of a Kamikaze: A World War II Pilot\u0026rsquo;s Inspiring Story of Survival, Honor and Reconciliation Thirty Minutes Over Oregon: A Japanese Pilot\u0026rsquo;s World War II Story ","date":"12 March, 2021","id":3,"permalink":"/reading-notes/2021-03-12-slaughterhouse-five/","summary":"\u003ch3 id=\"slaughterhouse-five\"\u003e\u003ca href=\"https://www.goodreads.com/book/show/4981.Slaughterhouse_Five\"\u003e\u003cem\u003eSlaughterhouse-Five\u003c/em\u003e by Kurt Vonnegut Jr.\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eI picked up a random book by Kurt Vonnegut Jr.,\nexpecting a science-fiction type of story,\nbut instead got a book about war.\u003c/p\u003e\n\u003cp\u003eI never liked books or movies about war,\nthey glorify it by telling stories of heroes and their gallantry,\nwhereas the dead sidekicks and other collateral damages barely constitute an afterthought.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;d hate to be such a sidekick,\nand hate it even more if I were such a hero.\u003c/p\u003e","tags":"","title":"Slaughterhouse-Five"},{"content":"Ham on Rye by Charles Bukowski I\u0026rsquo;ve been curious about the writings of Charles Bukowski for a while, mostly because of his dirty, subversive style.\nThis story delivers just that: a straight punch to the gut (there are many punches thrown in the book, both figurative and literal), packed with the hopelessness and disillusionment of being an outsider, and the rage of man against machine.\nAmong the many themes explored in the story, the one that resonated the most with me is how an individual can be totally powerless against the institution and the society at large. And the violence always makes me shudder. I don\u0026rsquo;t like violence, and wish it gone.\n","date":"7 February, 2021","id":4,"permalink":"/reading-notes/2021-02-07-ham_on_rye/","summary":"\u003ch3 id=\"ham-on-rye\"\u003e\u003ca href=\"https://www.goodreads.com/book/show/38501.Ham_on_Rye\"\u003e\u003cem\u003eHam on Rye\u003c/em\u003e by Charles Bukowski\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eI\u0026rsquo;ve been curious about the writings of Charles Bukowski for a while,\nmostly because of his dirty, subversive style.\u003c/p\u003e\n\u003cp\u003eThis story delivers just that:\na straight punch to the gut\n(there are many punches thrown in the book, both figurative and literal),\npacked with the hopelessness and disillusionment of being an outsider,\nand the rage of man against machine.\u003c/p\u003e\n\u003cp\u003eAmong the many themes explored in the story,\nthe one that resonated the most with me is how an individual can be totally powerless against the institution and the society at large.\nAnd the violence always makes me shudder.\nI don\u0026rsquo;t like violence, and wish it gone.\u003c/p\u003e","tags":"","title":"Ham on Rye"},{"content":"I took part in the recently-finished ML Reproducibility Challenge 2020, and together with a great team we attempted to reproduce one of the papers as part of a course assignment.\nThis is just my attempt to get back to blogging, as well as writing down some lessons learned. It\u0026rsquo;s by no means a criticism of anything, but lately I\u0026rsquo;ve realised if I don\u0026rsquo;t write things down I\u0026rsquo;ll most likely forget all about it in two or three months.\nShort story is, we couldn\u0026rsquo;t completely reproduce the original paper results. From my limited sample size of talking to and listening to presentations of my fellow students participating in this challenge, it seems like it\u0026rsquo;s quite common to not be able to reproduce a paper\u0026rsquo;s results completely, not in four weeks at least. That\u0026rsquo;s not as optimistic as I had thought.\nIn a way my group already had a head start, because the paper we tried to reproduce already came with some pretty extensive code, nuts and bolts included. But after scrolling through pages after pages, we realised this code is adapted from another paper, so there are a lot of dangling variables and unfinished experiments hidden inside, and at times this could be really confusing.\nBeing the overachieving students that we are, in the very beginning of our reproducibility study we were already thinking about the million different ways we could test this model or examine the authors\u0026rsquo; claims under more general settings. But training these babies is slow, so it\u0026rsquo;s quite easy to get discouraged by the progress. Then I felt somewhat swamped in discussions that were mostly speculation rather than factually grounded. That coupled with (almost) midnight zoom meetings was definitely not helpful for my sleep quality.\nOverall the experience was a very rewarding one, and I want to try to summarise what I observed/learned:\nDocument your code. Remove the bits in your code that you don\u0026rsquo;t actually use. Test your code. Don\u0026rsquo;t write one thing and your code is actually doing another (wildly different thing). At my previous job they made sure we read this book: Clean Code, or at least get the gist of it. I think that\u0026rsquo;s a pretty good idea, even if you\u0026rsquo;re \u0026ldquo;just a data guy/gal/person\u0026rdquo;. Optimise your code so it doesn\u0026rsquo;t take an insane amount of time (1.5 days! on a NVIDIA 1080 Ti) to train a not-grossly-complex model. Related to the previous point, make sure you\u0026rsquo;re not fine-tuning parameters that you don\u0026rsquo;t actually want to change, such as embeddings, unless that\u0026rsquo;s your intention. If the dataset only has a train/test split, and you would also want a dev split, it\u0026rsquo;s better to shave it off from the test part rather than train part, otherwise you might overfit your model because your train set and dev set is too similar/correlated. Train a model and evaluate multiple times with different seeds to make sure you\u0026rsquo;re not just getting lucky with your results. Report your hyper-parameters. Report your complete results (in an appendix or supplementary materials), don\u0026rsquo;t cherry-pick or leave the impression of cherry-picking your results just to support your claim. It\u0026rsquo;s probably not a good idea to use the same metric to evaluate different datasets/tasks. An accuracy improvement from 65% to 67% is not as awe-inspiring as an improvement from 95% to 97%. Don\u0026rsquo;t speculate before you get your results from the experiments (talking to myself right now :D). It\u0026rsquo;s easier to come up with one plan after you have solid results than to have ten contingency plans before seeing any actual numbers. I actually think the scientific community would be much happier and we\u0026rsquo;d be making much better progress as a whole if we all publish \u0026ldquo;failed\u0026rdquo; experiments rather than just those shiny ones. Knowing what will not work and what not to do is, in my opinion, much more helpful for gaining new insights and coming up with new ideas to experiment with.\nMaybe we need to start a negative-arXiv to host the dumb, the unglorious and the unprestigious.\n","date":"2 February, 2021","id":5,"permalink":"/blogs/2021-02-02lessons_learned_rc2020/","summary":"\u003cp\u003eI took part in the recently-finished \u003ca href=\"https://paperswithcode.com/rc2020\"\u003eML Reproducibility Challenge 2020\u003c/a\u003e, and \u003ca href=\"https://github.com/MotherOfUnicorns/FACT_AI_project\"\u003etogether with a great team\u003c/a\u003e we attempted to reproduce one of the papers as part of a course assignment.\u003c/p\u003e\n\u003cp\u003eThis is just my attempt to get back to blogging, as well as writing down some lessons learned.\nIt\u0026rsquo;s by no means a criticism of anything, but lately I\u0026rsquo;ve realised if I don\u0026rsquo;t write things down I\u0026rsquo;ll most likely forget all about it in two or three months.\u003c/p\u003e","tags":"","title":"Lessons Learned from RC2020"},{"content":"You can find some of the recipes I collected here.\nBon appétit!\n","date":"4 December, 2020","id":6,"permalink":"/recipes/","summary":"\u003cp\u003eYou can find some of the recipes I collected \u003ca href=\"http://yunli.nl/recipes/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eBon appétit!\u003c/p\u003e","tags":"","title":"Recipes"},{"content":"\nAutumn 2020 II, watercolour\nAutumn 2020 is still an autumn.\n","date":"25 October, 2020","id":7,"permalink":"/sketchbook/2020-10-25_autumn2/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-10-25_autumn2.png\" alt=\"Autumn 2020 II\" title=\"Autumn 2020 II\"\u003e\u003c/p\u003e","tags":"","title":"Autumn 2020 II"},{"content":"\nAutumn 2020 I, watercolour\nAutumn 2020 is still an autumn.\n","date":"25 October, 2020","id":8,"permalink":"/sketchbook/2020-10-25_autumn1/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-10-25_autumn1.png\" alt=\"Autumn 2020 I\" title=\"Autumn 2020 I\"\u003e\u003c/p\u003e","tags":"","title":"Autumn 2020 I"},{"content":"I was very excited to go back to school to once again bask in the glory of education and inch closer to becoming a virtuous woman. But the gods have not been kind, and more importantly, the humans have not been able enough to trust and be trusted and keep the virus at bay through concerted efforts. So even though I really miss the chance to meet people and talk to them once a week, I\u0026rsquo;ve decided to stay at home and avoid university campuses for a while. Especially since my age group has the highest infection rate right now. You never know.\nThat said, I also want to know: in the (near?) future, when can I go back to school?\nThere must be a number \u0026ndash; a magical indicator \u0026ndash; that will signal my return.\nI thought I would start with the infection rate, or perhaps the rate of positively tested cases daily as an estimate of how many people around me are infected. But not everyone getting tested will be roaming the street, so it\u0026rsquo;s not likely that I will encounter them. Also a person who\u0026rsquo;s feeling completely fine is probably less interested in getting their brain swabbed.\nThat\u0026rsquo;s too many twists and turns to reason about. I needed something rough. So here\u0026rsquo;s another thought: every day there are more people tested positive. Over a short period (say 3 days) this number does not (yet) fluctuate very wildly. So why not use the number of daily new cases as a substitute for people carrying the virus that are roaming the streets 3 days ago? And to take it further, why no use the number of daily new cases as a substitute for people carrying the virus that are roaming the streets now?\nMany problems with this assumption exist, true. But it\u0026rsquo;s the most readily available number.\nNext, the classic i.i.d. assumption: that everyone in the country are equally likely to carry the virus, and one person\u0026rsquo;s chance of being infected has no influence on others (say their family members or friends with whom they meet often).\nAnother bad assumption! But why not, this is a rough estimate.\nThe rest of the things fall into place very quickly.\nIf s is the number of daily new cases, P the total population of the country/province/whatever, N the number of people I meet/share a room with every time I venter out of my home into the university campus, then the probability of no one I meet is carrying the virus is\n(1 - s/P)^N So the probability of at least one person is carrying the virus is\n1 - (1 - s/P)^N If I accept at most a = 0.1% risk of meeting someone who carries the virus, then I can formulate it as\n1 - (1 - s/P)^N \u0026lt;= a (1 - s/P)^N \u0026gt;= 1 - a 1 - s/P \u0026gt;= (1 - a)^(1/N) s/P \u0026lt;= 1 - (1 - a)^(1/N) s \u0026lt;= P(1 - (1 - a)^(1/N)) Since I\u0026rsquo;m meeting about 20 people every time, for the population in the Netherlands and my appetite for risk, that works out to s = 850. Compared to the almost 3000 cases a day now, I can stay at home for a bit longer.\nIt\u0026rsquo;s pretty conservative, but I remember getting pneumonia as a kid, not a good feeling.\nI\u0026rsquo;m sure there are much better epidemiology models that can give you a smarter estimate. But I am now a committed woman (to homework and group projects) so a rough estimate will have to suffice.\nI do hope that day comes soon.\n","date":"26 September, 2020","id":9,"permalink":"/blogs/2020-09-26-rough_estimate_when_to_go_to_school/","summary":"\u003cp\u003eI was very excited to go back to school to once again bask in the glory of education and inch closer to becoming a virtuous woman.\nBut the gods have not been kind, and more importantly, the humans have not been able enough to trust and be trusted and keep the virus at bay through concerted efforts.\nSo even though I really miss the chance to meet people and talk to them once a week, I\u0026rsquo;ve decided to stay at home and avoid university campuses for a while.\nEspecially since \u003ca href=\"https://www.rivm.nl/documenten/wekelijkse-update-epidemiologische-situatie-covid-19-in-nederland\"\u003emy age group has the highest infection rate right now\u003c/a\u003e.\nYou never know.\u003c/p\u003e","tags":"","title":"Rough Estimate: When to go back to school?"},{"content":"\nDissociate II, watercolour\n","date":"10 September, 2020","id":10,"permalink":"/sketchbook/2020-09-10_dissociate2/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-09-10_dissociate2.jpg\" alt=\"Dissociate II\" title=\"Dissociate II\"\u003e\u003c/p\u003e","tags":"","title":"Dissociate II"},{"content":"\nDissociate I, watercolour\n","date":"23 August, 2020","id":11,"permalink":"/sketchbook/2020-08-23_dissociate1/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-08-23_dissociate1.jpg\" alt=\"Dissociate I\" title=\"Dissociate I\"\u003e\u003c/p\u003e","tags":"","title":"Dissociate I"},{"content":"I have a couple of scripts that I\u0026rsquo;d like to run at night, but I also want to leave my machine suspended to RAM overnight to conserve energy (and reduce noise, the fan is a beast!). So this is just a note for myself about how I went about it this time, using rtcwake and crontab.\nHere\u0026rsquo;s the crontab I originally had, which is triggered once a day in the afternoon:\n59 15 * * * /some/bash/script.sh But now I want to run it at night, when I\u0026rsquo;m not around my computer, which like me is probably also asleep. So I need to make sure the machine is in an awake state just before the cron jobs are scheduled to be executed.\nSome minutes of DuckDuckGo later I found rtcwake, which uses the hardware clock on the motherboard to send a signal to wake up the machine at desired time. Sounds like exactly what I need.\nSo now my crontab becomes:\n1 4 * * * sudo rtcwake -m no -t $(date +\\%s -d \u0026#34;tomorrow 03:55\u0026#34;) 59 3 * * * /some/bash/script.sh Some explanations:\nrtcwake needs root permission, hence the sudo. The -m no flag only sets an alert to wake up the machine. If the machine is already awake, nothing will change. The main idea is to start a cycle: rtcwake wakes up the machine (03:55) a few minutes before the scheduled cron job (03:59), and then another cron job (04:01) uses rtcwake to set up the next alert for tomorrow. After everything is done, the machine will go to sleep after 30 minutes according to some other energy saving settings I have. I waited for one night, but it did not work as I expected (it\u0026rsquo;s the first-time-never-works-law).\nBecause rtcwake requires root permission, it needs the root password when that cron job is run. But given it\u0026rsquo;s a bad idea to store root passwords anywhere it\u0026rsquo;s better to use root\u0026rsquo;s crontab instead of the one owned by the user. In other words, it would be two separate crontabs:\nwith sudo crontab -e:\n1 4 * * * sudo rtcwake -m no -t $(date +\\%s -d \u0026#34;tomorrow 03:55\u0026#34;) with your regular crontab -e (of course, this can also be run under root\u0026rsquo;s crontab, but I don\u0026rsquo;t want to clutter that up):\n59 3 * * * /some/bash/script.sh Et voilà, it\u0026rsquo;s as sweet as a dream, pun intended.\nThe only issue is if your machine restarts during the day and failed to run the crontab containing rtcwake, you\u0026rsquo;ll have to do it manually once to get the cycle started.\n","date":"17 August, 2020","id":12,"permalink":"/quick-fixes/2020-08-17_waking_up_with_rtcwake_and_crontab/","summary":"\u003cp\u003eI have a couple of scripts that I\u0026rsquo;d like to run at night, but I also want to leave my machine suspended to RAM overnight to conserve energy (and reduce noise, the fan is a beast!). So this is just a note for myself about how I went about it this time, using \u003ccode\u003ertcwake\u003c/code\u003e and \u003ccode\u003ecrontab\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eHere\u0026rsquo;s the crontab I originally had, which is triggered once a day in the afternoon:\u003c/p\u003e","tags":"","title":"Waking Up with rtcwake and crontab"},{"content":"\nAnother Random Portrait, watercolour\n","date":"8 August, 2020","id":13,"permalink":"/sketchbook/2020-08-08_portrait/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-08-08_portrait.jpg\" alt=\"Another Random Portrait\" title=\"Another Random Portrait\"\u003e\u003c/p\u003e","tags":"","title":"Another Random Portrait"},{"content":"\nMauve, watercolour\n","date":"7 August, 2020","id":14,"permalink":"/sketchbook/2020-08-07_mauve/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-08-07_mauve.jpg\" alt=\"Mauve\" title=\"Mauve\"\u003e\u003c/p\u003e","tags":"","title":"Mauve"},{"content":"\nWine, watercolour\n","date":"6 August, 2020","id":15,"permalink":"/sketchbook/2020-08-06_wine/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-08-06_wine.jpg\" alt=\"Wine\" title=\"Wine\"\u003e\u003c/p\u003e","tags":"","title":"Wine"},{"content":"\nValue study, watercolour\n","date":"24 July, 2020","id":16,"permalink":"/sketchbook/2020-07-24_value_study/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-07-24_value_study.jpg\" alt=\"Value Study\" title=\"Value Study\"\u003e\u003c/p\u003e","tags":"","title":"Value Study"},{"content":"I never seem to have got into the habit of writing tests as I code. That\u0026rsquo;s bad, I know.\nBut there are so many excuses that prevents it, \u0026ldquo;oh this is just an exploratory thing\u0026rdquo;, or \u0026ldquo;Karen and Chad really needs the report/tool soon, no time for test\u0026rdquo;, or whatever else that might get in your way. Plus there\u0026rsquo;s a tendency to just use the million open-source projects out-of-the box, and expect them to do what you think they do.\nSometimes they don\u0026rsquo;t work they way you had hoped, and you end up digging thought lines and lines of code hoping to find out what went wrong where. And if you\u0026rsquo;re working with particularly large datasets, just the IO along can slow you down very considerably. Or worse yet, you merrily hand over a \u0026ldquo;finished product\u0026rdquo; without even realising the bugs inside \u0026ndash; because no tests told you so! I can personally attest to this, especially those deadline-rushed projects.\nWell, this time I did it again. I\u0026rsquo;m about a thousand line deep into my autotrader project, when I realised my features are being scaled in inconsistent ways, that I though of \u0026ldquo;hmm, maybe there should be a test for this\u0026hellip;\u0026rdquo;\nIt\u0026rsquo;s a very simple operation, take all the values of one feature in the training dataset, subtract the mean, and divide by the standard deviation. The default behaviour of sklearn.preprocessing.StandardScaler takes the population standard deviation, meaning it\u0026rsquo;s normalised by N, the sample size, whereas the default behaviour of pandas.DataFrame.std calculates standard deviation with N-1, which is what I expected.\nI went back and created a toy dataset, and wrote my own test for my functions and modules which scale different types of features. And many more tests for other functions and modules. I spent a whole week catching up with writing tests. During the process I also refactored some of my maybe-a-bit-too-long functions, so that they\u0026rsquo;re easier to test, and also easier to read.\nGranted, bugs are ever-elusive, and no amount of testing can ensure you don\u0026rsquo;t ever make mistakes. But I would sleep better at night. (It\u0026rsquo;s also a great feeling to watch your tests pass one by one, and the green dots appear one after another. So satisfying.)\nJust write some tests, it\u0026rsquo;s better late than never.\n","date":"3 July, 2020","id":17,"permalink":"/blogs/2020-07-03-write_tests/","summary":"\u003cp\u003eI never seem to have got into the habit of writing tests as I code. That\u0026rsquo;s bad, I know.\u003c/p\u003e\n\u003cp\u003eBut there are so many excuses that prevents it, \u0026ldquo;oh this is just an exploratory thing\u0026rdquo;, or \u0026ldquo;Karen and Chad really needs the report/tool soon, no time for test\u0026rdquo;, or whatever else that might get in your way. Plus there\u0026rsquo;s a tendency to just use the million open-source projects out-of-the box, and expect them to do what you think they do.\u003c/p\u003e","tags":"","title":"Write Tests for Your Data Science Project"},{"content":"\nPeaches, watercolour\n","date":"2 July, 2020","id":18,"permalink":"/sketchbook/2020-07-02_assholes/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-07-02_peaches.jpg\" alt=\"Peaches\" title=\"Peaches\"\u003e\u003c/p\u003e","tags":"","title":"Peaches"},{"content":"Time zone is such a messy subject, and I don\u0026rsquo;t even know what to start with.\nAt my previous job I had this photo saved from a stackoverflow answer:\nso that every time I need to do some time zone conversion magic, I have a quick reference to go to. Because seriously, how do you expect anyone to memorize all that?\nToday I\u0026rsquo;m playing with some time zone stuff again for the API with my autotrader database, and encountered a new problem/feature that somehow entirely evaded my attention in the past. In a nutshell, these two code blocks produced different results, and I couldn\u0026rsquo;t understand why:\nuse tzinfo=... when creating a datetime.datetime object\nimport datetime as dt from pytz import timezone tz = timezone(\u0026#39;Europe/Amsterdam\u0026#39;) dt.datetime(2020, 2, 1, 10, tzinfo=tz) which produces this result:\ndatetime.datetime(2020, 2, 1, 10, 0, tzinfo=\u0026lt;DstTzInfo \u0026#39;Europe/Amsterdam\u0026#39; LMT+0:20:00 STD\u0026gt;) use timezone.localize() on an existing datetime.datetime object\ntz = timezone(\u0026#39;Europe/Amsterdam\u0026#39;) tz.localize(dt.datetime(2020, 2, 1, 10)) which gives this:\ndatetime.datetime(2020, 2, 1, 10, 0, tzinfo=\u0026lt;DstTzInfo \u0026#39;Europe/Amsterdam\u0026#39; CET+1:00:00 STD\u0026gt;) Why are they not the same???\nAnswer is, method #1 returns a time offset which is the Local Mean Time (LMT), which is purely decided by the longitude of the location in question. On the other hand, method #2 gives the actual time zone, which is more of a social structure than a geological one, and that is what I wanted.\nHere CET stands for Central European Time, which is the time zone observed in the Netherlands.\nI didn\u0026rsquo;t feel like using any third-party packages like Arrow or Pendulum. They each have their own nice features, but integrating them with other libraries (like SQLAlchemy I\u0026rsquo;m using) sometimes is a bit messy (and more work to do).\nMaybe at some point I\u0026rsquo;ll end up writing a series about how I approach time zones. Part of me still hopes that we\u0026rsquo;ll all switch to UTC some time soon. Or at least, get rid of daylight saving.\n","date":"9 June, 2020","id":19,"permalink":"/quick-fixes/2020-06-09-timezone_in_python/","summary":"\u003cp\u003eTime zone is such a messy subject, and I don\u0026rsquo;t even know what to start with.\u003c/p\u003e\n\u003cp\u003eAt my previous job I had this photo saved from a \u003ca href=\"https://stackoverflow.com/questions/13703720/converting-between-datetime-timestamp-and-datetime64\"\u003estackoverflow answer\u003c/a\u003e:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://i.stack.imgur.com/uiXQd.png\" alt=\"time zone conversion\"\u003e\u003c/p\u003e\n\u003cp\u003eso that every time I need to do some time zone conversion magic, I have a quick reference to go to. Because seriously, how do you expect anyone to memorize all that?\u003c/p\u003e\n\u003cp\u003eToday I\u0026rsquo;m playing with some time zone stuff again for the API with my autotrader database, and encountered a new problem/feature that somehow entirely evaded my attention in the past. In a nutshell, these two code blocks produced different results, and I couldn\u0026rsquo;t understand why:\u003c/p\u003e","tags":"","title":"Time Zone in Python - Tip of the Iceberg"},{"content":"\nportrait sketch using an old magazine as reference, graphite pencil\n","date":"2 June, 2020","id":20,"permalink":"/sketchbook/2020-06-02-portrait/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-06-02-portrait.jpeg\" alt=\"portrait\" title=\"portrait\"\u003e\u003c/p\u003e","tags":"","title":"Random Portrait"},{"content":"When handling timeseries data, quite often you may want to resample the data at a different frequency and use it that way.\nOne way to achieve this is to load all data with Python, and resample or reindex it with Pandas.\nAn alternative is to query directly in SQL by using a pattern like the one below. This allows you to only get the most recent data at each sample point you\u0026rsquo;re interested in. This particular example samples the exchange rate between JPY and USD every two hours (in the actual database, I have some more recent data at 1 min intervals, and the rest at either 5 min or 30 min intervals):\nselect * from generate_series(\u0026#39;2020-01-01\u0026#39;, \u0026#39;2020-01-15\u0026#39;, \u0026#39;2 hour\u0026#39;::interval) sampled_at join lateral ( select * from alphavantage.fx f where f.ts \u0026lt;= sampled_at and currency_from = \u0026#39;JPY\u0026#39; and currency_to = \u0026#39;USD\u0026#39; order by f.ts desc limit 1 ) p on true Since I\u0026rsquo;m down on the SQLAlchemy ORM road, why not try to write the query there as well!\nI found the SQLAlchemy documentation quite difficult to grapple with at times, and I get the impression that there are many, many different ways to accomplish the same thing. At some point I got quite overwhelmed and frustrated after reading page after page of docs that doesn\u0026rsquo;t directly answer the question I have.\nThen I came across this blog post by Adam Gligor, which really helped me comb my thoughts and finally decide on how I want to approach it.\nFirst take care of all the imports:\nimport datetime as dt from sqlalchemy import and_, desc, true from sqlalchemy.orm import aliased, sessionmaker from sqlalchemy.sql import func from sqlalchemy.sql.expression import join from .constants import DB_ENGINE from .models import FxPrice _Session = sessionmaker(bind=DB_ENGINE) session = _Session() I wrote this subquery to generate timeseries that I want to resample the data on, and aliased it:\nstart_ts, end_ts = dt.datetime(2020, 1, 1), dt.datetime(2020, 2, 1) interval = dt.timedelta(hours=2) subquery_ts = ( session.query( func.generate_series(start_ts, end_ts, interval).label( \u0026#34;sampled_at\u0026#34; ) ) .subquery() .lateral() ) a = aliased(subquery_ts) The aliased() function does something like this in SQL:\nselect * from some_table as some_alias ... It essentially allows you to give a name to some (intermediate or temporary) table, so that you can reference it later, either when joining it with another table, or joining it with itself.\nThen I wrote another subquery to get the most recent price update at each time point I want to sample. Note that here I compared the timestamp in FxPrice table with a.c.sampled_at, where a is the aforementioned alias to the table created using generate_series. (The .c in a.c is for columns, so a.c.sampled_at gets you the column named sampled_at.)\nWithout the aliasing I wouldn\u0026rsquo;t be able to achieve this effect; instead it would create a nested subquery and that\u0026rsquo;s not what I want.\nsubquery_price = ( session.query(FxPrice) .filter( and_( FxPrice.ts \u0026lt;= a.c.sampled_at, FxPrice.currency_from == \u0026#34;JPY\u0026#34;, FxPrice.currency_to == \u0026#34;USD\u0026#34;, ) ) .order_by(desc(FxPrice.ts)) .limit(1) .subquery() .lateral() ) Finally, putting everything together:\nresults = ( session.query( subquery_price.c.ts, a, subquery_price.c.currency_from, subquery_price.c.currency_to, subquery_price.c.price, ) .select_from(a) .join(subquery_price, true()) .all() ) Which actually produces the following query:\nSELECT anon_1.ts, anon_2.sampled_at, anon_1.currency_from, anon_1.currency_to, anon_1.price FROM ( SELECT generate_series(:generate_series_1, :generate_series_2, :generate_series_3) AS sampled_at ) AS anon_2 JOIN LATERAL ( SELECT alphavantage.fx.created_at AS created_at, alphavantage.fx.ts AS ts, alphavantage.fx.currency_from AS currency_from, alphavantage.fx.currency_to AS currency_to, alphavantage.fx.price AS price FROM alphavantage.fx WHERE alphavantage.fx.ts \u0026lt;= anon_2.sampled_at AND alphavantage.fx.currency_from = :currency_from_1 AND alphavantage.fx.currency_to = :currency_to_1 ORDER BY alphavantage.fx.ts DESC LIMIT :param_1 ) AS anon_1 ON true where the parameters are:\n{ \u0026#39;generate_series_1\u0026#39;: datetime.datetime(2020, 1, 1, 0, 0), \u0026#39;generate_series_2\u0026#39;: datetime.datetime(2020, 2, 1, 0, 0), \u0026#39;generate_series_3\u0026#39;: datetime.timedelta(seconds=7200), \u0026#39;currency_from_1\u0026#39;: \u0026#39;JPY\u0026#39;, \u0026#39;currency_to_1\u0026#39;: \u0026#39;USD\u0026#39;, \u0026#39;param_1\u0026#39;: 1 } ","date":"2 June, 2020","id":21,"permalink":"/quick-fixes/2020-05-02-lateral_join_orm/","summary":"\u003cp\u003eWhen handling timeseries data, quite often you may want to resample the data at a different frequency and use it that way.\u003c/p\u003e\n\u003cp\u003eOne way to achieve this is to load all data with Python, and \u003ca href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html\"\u003eresample\u003c/a\u003e or \u003ca href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reindex.html\"\u003ereindex\u003c/a\u003e it with Pandas.\u003c/p\u003e\n\u003cp\u003eAn alternative is to query directly in SQL by using a pattern like the one below. This allows you to only get the most recent data at each sample point you\u0026rsquo;re interested in. This particular example samples the exchange rate between JPY and USD every two hours (in the actual database, I have some more recent data at 1 min intervals, and the rest at either 5 min or 30 min intervals):\u003c/p\u003e","tags":"","title":"Lateral Join with SQLAlchemy"},{"content":"\nbay leaf from biryani, watercolour\n","date":"30 May, 2020","id":22,"permalink":"/sketchbook/2020-05-30-bay_leaf/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-05-30-bay_leaf.jpeg\" alt=\"bay leaf\" title=\"bay leaf\"\u003e\u003c/p\u003e","tags":"","title":"Bay Leaf"},{"content":"I recently started working on my own autotrader. There\u0026rsquo;s still much to be done, but I\u0026rsquo;ve finished the first step \u0026ndash; collecting data and put them in a database. I\u0026rsquo;ve got a PostgreSQL server running on Docker, and a script that reads data using the AlphaVantage API and writes to my database.\nThe next step would be to write my own Python API to query data from the database. The easy way for me would be to stick a bunch of SQL queries in some python functions, but why do that when you can make life more complicated! I\u0026rsquo;ve been wanting to learn about ORM, and decided this would be my chance to try it out with SQLAlchemy.\nforeign keys I first created these models:\nfrom sqlalchemy import Column, ForeignKey from sqlalchemy.dialects.postgresql import DOUBLE_PRECISION, TEXT, TIMESTAMP from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import relationship Base = declarative_base() class ModelMixin: __table_args__ = {\u0026#34;schema\u0026#34;: \u0026#34;alphavantage\u0026#34;} created_at = Column(TIMESTAMP(timezone=True)) class Currency(Base, ModelMixin): __tablename__ = \u0026#34;currencies\u0026#34; currency = Column(TEXT, primary_key=True) class FxPrice(Base, ModelMixin): __tablename__ = \u0026#34;fx\u0026#34; ts = Column(TIMESTAMP(timezone=True), primary_key=True) currency_from = Column( TEXT, ForeignKey(\u0026#34;currencies.currency\u0026#34;), primary_key=True ) currency_to = Column( TEXT, ForeignKey(\u0026#34;currencies.currency\u0026#34;), primary_key=True ) price = Column(DOUBLE_PRECISION) _currency_from = relationship(\u0026#34;Currency\u0026#34;, foreign_keys=[currency_from]) _currency_to = relationship(\u0026#34;Currency\u0026#34;, foreign_keys=[currency_to]) With an existing database, my goal is to reproduce the tables with a SQLAlchemy model, so I can interact with the database through this bit of Python code.\nBut it didn\u0026rsquo;t work, and kept producing this error:\nsqlalchemy.exc.NoReferencedTableError: Foreign key associated with column \u0026#39;fx.currency_from\u0026#39; could not find table \u0026#39;currencies\u0026#39; with which to generate a foreign key to target column \u0026#39;currency\u0026#39; After much digging, I found this is because the tables are not in the default public schema, and the solution is to specify schema name while declaring the columns with foreign keys:\ncurrency_from = Column( TEXT, ForeignKey(\u0026#34;alphavantage.currencies.currency\u0026#34;), primary_key=True ) currency_to = Column( TEXT, ForeignKey(\u0026#34;alphavantage.currencies.currency\u0026#34;), primary_key=True ) alembic Alembic is a tool for helping with database migrations. It helps tie together your SQLAlchemy models with tables in your database, so that any change you make in your ORM model (e.g. add a column, introduce a new table, etc) will be automatically reflected in your databse.\nIt was quite easy to set up, but when I ran\nalembic revision --autogenerate alembic upgrade head --sql to try it out, it ended up trying to create two new tables in my database public.\u0026quot;alphavantage.currencies\u0026quot; and public.\u0026quot;alphavantage.fx\u0026quot;. The expected behaviour is to do nothing, because those two tables already exist in my database.\nApparenly, by default, alembic only discovers tables in the default schema. In this case the tables are in a different alphavantage schema, and that caused some confusion.\nTo change its default behaviour, locate the env.py file in ./alembic, and add this line\ninclude_schemas=True in the bit about\ncontext.configure() of both of these two functions\ndef run_migrations_offline(): ... def run_migrations_online() ... conclusion Maybe check your schema names when SQLAlchemy can\u0026rsquo;t seem find a table that actually exists!\n","date":"28 May, 2020","id":23,"permalink":"/quick-fixes/2020-05-28-schema_name/","summary":"\u003cp\u003eI recently started working on my own autotrader. There\u0026rsquo;s still much to be done, but I\u0026rsquo;ve finished the first step \u0026ndash; collecting data and put them in a database. I\u0026rsquo;ve got a PostgreSQL server running on Docker, and a script that reads data using the \u003ca href=\"https://www.alphavantage.co/documentation/\"\u003eAlphaVantage API\u003c/a\u003e and writes to my database.\u003c/p\u003e\n\u003cp\u003eThe next step would be to write my own Python API to query data from the database. The easy way for me would be to stick a bunch of SQL queries in some python functions, but why do that when you can make life more complicated! I\u0026rsquo;ve been wanting to learn about \u003ca href=\"https://en.wikipedia.org/wiki/Object-relational_mapping\"\u003eORM\u003c/a\u003e, and decided this would be my chance to try it out with SQLAlchemy.\u003c/p\u003e","tags":"","title":"Schema Names: SQLAlchemy and Alembic"},{"content":"\nsunflower, watercolour\n","date":"24 May, 2020","id":24,"permalink":"/sketchbook/2020-05-24-sunflower/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-05-24-sunflower.jpeg\" alt=\"sunflower\" title=\"sunflower\"\u003e\u003c/p\u003e","tags":"","title":"Sunflower"},{"content":"\nparakeet, watercolour\n","date":"10 May, 2020","id":25,"permalink":"/sketchbook/2020-05-10-parakeet/","summary":"\u003cp\u003e\u003cimg src=\"/sketchbook/2020-05-10-parakeet.jpg\" alt=\"parakeet\" title=\"parakeet\"\u003e\u003c/p\u003e","tags":"","title":"Parakeet"},{"content":"Hi, I\u0026rsquo;m Yun, and welcome to my site.\nI\u0026rsquo;m a data scientist, and I also like tinkering with things, taking photos, and drawing. Here\u0026rsquo;s one of the corners where I document what I do.\nFor business inquiries, please visit AmphibiousUnicorns.com.\nwork \u0026amp; study Optiver (2017-2020) AMOLF (2016-2017) XtalPi (2015) Amsterdam University College (2014-2017) BSc. liberal arts and sciences, focus on physics Hong Kong Baptist University (2012-2014) unfinished BSc. applied and computational mathematics social \u0026amp; contact GitHub LinkedIn Instagram, another Instagram flickr goodreads email ","date":"23 April, 2020","id":26,"permalink":"/about/","summary":"\u003cp\u003eHi, I\u0026rsquo;m Yun, and welcome to my site.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m a data scientist, and I also like tinkering with things, taking photos, and drawing. Here\u0026rsquo;s one of the corners where I document what I do.\u003c/p\u003e\n\u003cp\u003eFor business inquiries, please visit \u003ca href=\"https://amphibiousunicorns.com\"\u003eAmphibiousUnicorns.com\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"work--study\"\u003ework \u0026amp; study\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.optiver.com/eu/en/\"\u003eOptiver\u003c/a\u003e (2017-2020)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://amolf.nl/\"\u003eAMOLF\u003c/a\u003e (2016-2017)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.xtalpi.com/en/\"\u003eXtalPi\u003c/a\u003e (2015)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.auc.nl/\"\u003eAmsterdam University College\u003c/a\u003e (2014-2017)\n\u003cul\u003e\n\u003cli\u003eBSc. liberal arts and sciences, focus on physics\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.hkbu.edu.hk/eng/main/index.jsp\"\u003eHong Kong Baptist University\u003c/a\u003e (2012-2014)\n\u003cul\u003e\n\u003cli\u003eunfinished BSc. applied and computational mathematics\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"social--contact\"\u003esocial \u0026amp; contact\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/MotherOfUnicorns\"\u003eGitHub\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.linkedin.com/in/yun-li/\"\u003eLinkedIn\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.instagram.com/yunthemotherofunicorns/\"\u003eInstagram\u003c/a\u003e, another \u003ca href=\"https://www.instagram.com/uselessplasticwraps/\"\u003eInstagram\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://flickr.com/photos/40302242@N08/\"\u003eflickr\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.goodreads.com/meiyousonghuadan\"\u003egoodreads\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"mailto:liyun.elf[_at_]gmail.com\"\u003eemail\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","tags":"","title":"About"},{"content":"Building my site.\n","date":"23 April, 2020","id":27,"permalink":"/blogs/2020-04-23-first_post/","summary":"\u003cp\u003eBuilding my site.\u003c/p\u003e","tags":"","title":"My First Post"}]