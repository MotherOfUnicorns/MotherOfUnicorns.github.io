
{
    "version": "https://jsonfeed.org/version/1.1",
    "title": "Blogs on yun's attic",
    "description": "Recent content in Blogs on yun's attic",
    "home_page_url": "https://yunli.nl/",
    "feed_url": "https://yunli.nl/blogs/index.json",
    "language": "en-GB",
    "icon": "https://yunli.nl/images/logo.png",
    "favicon": "https://yunli.nl/images/logo.png",
    "authors": [
        {
            "name": "yun li",
            "url": "https://yunli.nl"
        }
    ],
    "items": [
        {
            "title": "Lessons Learned from RC2020",
            "date_published": "2021-02-02T20:56:27+01:00",
            "date_modified": "2021-02-02T20:56:27+01:00",
            "id": "https://yunli.nl/blogs/2021-02-02lessons_learned_rc2020/",
            "url": "https://yunli.nl/blogs/2021-02-02lessons_learned_rc2020/",
            "content_html": "\u003cp\u003eI took part in the recently-finished \u003ca href=\"https://paperswithcode.com/rc2020\"\u003eML Reproducibility Challenge 2020\u003c/a\u003e, and \u003ca href=\"https://github.com/MotherOfUnicorns/FACT_AI_project\"\u003etogether with a great team\u003c/a\u003e we attempted to reproduce one of the papers as part of a course assignment.\u003c/p\u003e\n\u003cp\u003eThis is just my attempt to get back to blogging, as well as writing down some lessons learned.\nIt\u0026rsquo;s by no means a criticism of anything, but lately I\u0026rsquo;ve realised if I don\u0026rsquo;t write things down I\u0026rsquo;ll most likely forget all about it in two or three months.\u003c/p\u003e\n\u003cp\u003eShort story is, we couldn\u0026rsquo;t completely reproduce the original paper results. From my limited sample size of talking to and listening to presentations of my fellow students participating in this challenge, it seems like it\u0026rsquo;s quite common to \u003cem\u003e\u003cstrong\u003enot\u003c/strong\u003e\u003c/em\u003e be able to reproduce a paper\u0026rsquo;s results completely, not in four weeks at least. That\u0026rsquo;s not as optimistic as I had thought.\u003c/p\u003e\n\u003cp\u003eIn a way my group already had a head start, because the paper we tried to reproduce already came with some pretty extensive code, nuts and bolts included.\nBut after scrolling through pages after pages, we realised this code is adapted from another paper, so there are a lot of dangling variables and unfinished experiments hidden inside, and at times this could be really confusing.\u003c/p\u003e\n\u003cp\u003eBeing the overachieving students that we are, in the very beginning of our reproducibility study we were already thinking about the million different ways we could test this model or examine the authors\u0026rsquo; claims under more general settings.\nBut training these babies is slow, so it\u0026rsquo;s quite easy to get discouraged by the progress.\nThen I felt somewhat swamped in discussions that were mostly speculation rather than factually grounded.\nThat coupled with (almost) midnight zoom meetings was definitely not helpful for my sleep quality.\u003c/p\u003e\n\u003cp\u003eOverall the experience was a very rewarding one, and I want to try to summarise what I observed/learned:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDocument your code.\u003c/li\u003e\n\u003cli\u003eRemove the bits in your code that you don\u0026rsquo;t actually use.\u003c/li\u003e\n\u003cli\u003eTest your code. Don\u0026rsquo;t write one thing and your code is actually doing another (wildly different thing).\u003c/li\u003e\n\u003cli\u003eAt my previous job they made sure we read this book: \u003ca href=\"https://www.goodreads.com/book/show/3735293-clean-code\"\u003e\u003cem\u003eClean Code\u003c/em\u003e\u003c/a\u003e, or at least get the gist of it. I think that\u0026rsquo;s a pretty good idea, even if you\u0026rsquo;re \u0026ldquo;just a data guy/gal/person\u0026rdquo;.\u003c/li\u003e\n\u003cli\u003eOptimise your code so it doesn\u0026rsquo;t take an insane amount of time (1.5 days! on a NVIDIA 1080 Ti) to train a not-grossly-complex model.\u003c/li\u003e\n\u003cli\u003eRelated to the previous point, make sure you\u0026rsquo;re not fine-tuning parameters that you don\u0026rsquo;t actually want to change, such as embeddings, unless that\u0026rsquo;s your intention.\u003c/li\u003e\n\u003cli\u003eIf the dataset only has a train/test split, and you would also want a dev split, it\u0026rsquo;s better to shave it off from the test part rather than train part, otherwise you might overfit your model because your train set and dev set is too similar/correlated.\u003c/li\u003e\n\u003cli\u003eTrain a model and evaluate multiple times with different seeds to make sure you\u0026rsquo;re not just getting lucky with your results.\u003c/li\u003e\n\u003cli\u003eReport your hyper-parameters.\u003c/li\u003e\n\u003cli\u003eReport your complete results (in an appendix or supplementary materials), don\u0026rsquo;t cherry-pick or leave the impression of cherry-picking your results just to support your claim.\u003c/li\u003e\n\u003cli\u003eIt\u0026rsquo;s probably not a good idea to use the same metric to evaluate different datasets/tasks. An accuracy improvement from 65% to 67% is not as awe-inspiring as an improvement from 95% to 97%.\u003c/li\u003e\n\u003cli\u003eDon\u0026rsquo;t speculate before you get your results from the experiments (talking to myself right now :D). It\u0026rsquo;s easier to come up with one plan after you have solid results than to have ten contingency plans before seeing any actual numbers.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eI actually think the scientific community would be much happier and we\u0026rsquo;d be making much better progress as a whole if we all publish \u0026ldquo;failed\u0026rdquo; experiments rather than just those shiny ones.\nKnowing what will not work and what not to do is, in my opinion, much more helpful for gaining new insights and coming up with new ideas to experiment with.\u003c/p\u003e\n\u003cp\u003eMaybe we need to start a negative-arXiv to host the dumb, the unglorious and the unprestigious.\u003c/p\u003e\n"
        },
        {
            "title": "Rough Estimate: When to go back to school?",
            "date_published": "2020-09-26T22:20:55+02:00",
            "date_modified": "2020-09-26T22:20:55+02:00",
            "id": "https://yunli.nl/blogs/2020-09-26-rough_estimate_when_to_go_to_school/",
            "url": "https://yunli.nl/blogs/2020-09-26-rough_estimate_when_to_go_to_school/",
            "content_html": "\u003cp\u003eI was very excited to go back to school to once again bask in the glory of education and inch closer to becoming a virtuous woman.\nBut the gods have not been kind, and more importantly, the humans have not been able enough to trust and be trusted and keep the virus at bay through concerted efforts.\nSo even though I really miss the chance to meet people and talk to them once a week, I\u0026rsquo;ve decided to stay at home and avoid university campuses for a while.\nEspecially since \u003ca href=\"https://www.rivm.nl/documenten/wekelijkse-update-epidemiologische-situatie-covid-19-in-nederland\"\u003emy age group has the highest infection rate right now\u003c/a\u003e.\nYou never know.\u003c/p\u003e\n\u003cp\u003eThat said, I also want to know: in the (near?) future, when can I go back to school?\u003c/p\u003e\n\u003cp\u003eThere must be a number \u0026ndash; a magical indicator \u0026ndash; that will signal my return.\u003c/p\u003e\n\u003cp\u003eI thought I would start with the infection rate, or perhaps the rate of positively tested cases daily as an estimate of how many people around me are infected.\nBut not everyone getting tested will be roaming the street, so it\u0026rsquo;s not likely that I will encounter them.\nAlso a person who\u0026rsquo;s feeling completely fine is probably less interested in getting their brain swabbed.\u003c/p\u003e\n\u003cp\u003eThat\u0026rsquo;s too many twists and turns to reason about. I needed something rough.\nSo here\u0026rsquo;s another thought: every day there are more people tested positive. Over a short period (say 3 days) this number does not (yet) fluctuate very wildly.\nSo why not use the number of daily new cases as a substitute for people carrying the virus that are roaming the streets 3 days ago?\nAnd to take it further, why no use the number of daily new cases as a substitute for people carrying the virus that are roaming the streets now?\u003c/p\u003e\n\u003cp\u003eMany problems with this assumption exist, true. But it\u0026rsquo;s the most readily available number.\u003c/p\u003e\n\u003cp\u003eNext, the classic i.i.d. assumption: that everyone in the country are equally likely to carry the virus, and one person\u0026rsquo;s chance of being infected has no influence on others (say their family members or friends with whom they meet often).\u003c/p\u003e\n\u003cp\u003eAnother bad assumption! But why not, this is a rough estimate.\u003c/p\u003e\n\u003cp\u003eThe rest of the things fall into place very quickly.\u003c/p\u003e\n\u003cp\u003eIf \u003ccode\u003es\u003c/code\u003e is the number of daily new cases, \u003ccode\u003eP\u003c/code\u003e the total population of the country/province/whatever, \u003ccode\u003eN\u003c/code\u003e the number of people I meet/share a room with every time I venter out of my home into the university campus, then the probability of no one I meet is carrying the virus is\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e(1 - s/P)^N\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eSo the probability of at least one person is carrying the virus is\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e1 - (1 - s/P)^N\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf I accept at most \u003ccode\u003ea = 0.1%\u003c/code\u003e risk of meeting someone who carries the virus, then I can formulate it as\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e1 - (1 - s/P)^N \u0026lt;= a\n    (1 - s/P)^N \u0026gt;= 1 - a\n        1 - s/P \u0026gt;= (1 - a)^(1/N)\n            s/P \u0026lt;= 1 - (1 - a)^(1/N)\n              s \u0026lt;= P(1 - (1 - a)^(1/N))\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eSince I\u0026rsquo;m meeting about 20 people every time, for the \u003ca href=\"https://en.wikipedia.org/wiki/Demography_of_the_Netherlands\"\u003epopulation in the Netherlands\u003c/a\u003e and my appetite for risk, that works out to \u003ccode\u003es = 850\u003c/code\u003e.\nCompared to the \u003ca href=\"https://www.rivm.nl/en/novel-coronavirus-covid-19/current-information\"\u003ealmost 3000 cases\u003c/a\u003e a day now, I can stay at home for a bit longer.\u003c/p\u003e\n\u003cp\u003eIt\u0026rsquo;s pretty conservative, but I remember getting pneumonia as a kid, not a good feeling.\u003c/p\u003e\n\u003cp\u003eI\u0026rsquo;m sure there are much better epidemiology models that can give you a smarter estimate.\nBut I am now a committed woman (to homework and group projects) so a rough estimate will have to suffice.\u003c/p\u003e\n\u003cp\u003eI do hope that day comes soon.\u003c/p\u003e\n"
        },
        {
            "title": "Write Tests for Your Data Science Project",
            "date_published": "2020-07-03T13:09:00+02:00",
            "date_modified": "2020-07-03T13:09:00+02:00",
            "id": "https://yunli.nl/blogs/2020-07-03-write_tests/",
            "url": "https://yunli.nl/blogs/2020-07-03-write_tests/",
            "content_html": "\u003cp\u003eI never seem to have got into the habit of writing tests as I code. That\u0026rsquo;s bad, I know.\u003c/p\u003e\n\u003cp\u003eBut there are so many excuses that prevents it, \u0026ldquo;oh this is just an exploratory thing\u0026rdquo;, or \u0026ldquo;Karen and Chad really needs the report/tool soon, no time for test\u0026rdquo;, or whatever else that might get in your way. Plus there\u0026rsquo;s a tendency to just use the million open-source projects out-of-the box, and expect them to do what you think they do.\u003c/p\u003e\n\u003cp\u003eSometimes they don\u0026rsquo;t work they way you had hoped, and you end up digging thought lines and lines of code hoping to find out what went wrong where. And if you\u0026rsquo;re working with particularly large datasets, just the IO along can slow you down very considerably. Or worse yet, you merrily hand over a \u0026ldquo;finished product\u0026rdquo; without even realising the bugs inside \u0026ndash; because no tests told you so! I can personally attest to this, especially those deadline-rushed projects.\u003c/p\u003e\n\u003cp\u003eWell, this time I did it again. I\u0026rsquo;m about a thousand line deep into my autotrader project, when I realised my features are being scaled in inconsistent ways, that I though of \u0026ldquo;hmm, maybe there should be a test for this\u0026hellip;\u0026rdquo;\u003c/p\u003e\n\u003cp\u003eIt\u0026rsquo;s a very simple operation, take all the values of one feature in the training dataset, subtract the mean, and divide by the standard deviation.\nThe default behaviour of \u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\"\u003e\u003ccode\u003esklearn.preprocessing.StandardScaler\u003c/code\u003e\u003c/a\u003e takes the population standard deviation, meaning it\u0026rsquo;s normalised by \u003ccode\u003eN\u003c/code\u003e, the sample size, whereas the default behaviour of \u003ca href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.std.html\"\u003e\u003ccode\u003epandas.DataFrame.std\u003c/code\u003e\u003c/a\u003e calculates standard deviation with \u003ccode\u003eN-1\u003c/code\u003e, which is what I expected.\u003c/p\u003e\n\u003cp\u003eI went back and created a toy dataset, and wrote my own test for my functions and modules which scale different types of features. And many more tests for other functions and modules. I spent a whole week catching up with writing tests. During the process I also refactored some of my maybe-a-bit-too-long functions, so that they\u0026rsquo;re easier to test, and also easier to read.\u003c/p\u003e\n\u003cp\u003eGranted, bugs are ever-elusive, and no amount of testing can ensure you don\u0026rsquo;t ever make mistakes. But I would sleep better at night. (It\u0026rsquo;s also a great feeling to watch your tests pass one by one, and the green dots appear one after another. So satisfying.)\u003c/p\u003e\n\u003cp\u003eJust write some tests, it\u0026rsquo;s better late than never.\u003c/p\u003e\n"
        },
        {
            "title": "My First Post",
            "date_published": "2020-04-23T17:12:14+02:00",
            "date_modified": "2020-04-23T17:12:14+02:00",
            "id": "https://yunli.nl/blogs/2020-04-23-first_post/",
            "url": "https://yunli.nl/blogs/2020-04-23-first_post/",
            "content_html": "\u003cp\u003eBuilding my site.\u003c/p\u003e\n"
        }
        ]
}
